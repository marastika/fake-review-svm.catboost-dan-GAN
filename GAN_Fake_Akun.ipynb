{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marastika/fake-review-svm.catboost-dan-GAN/blob/main/GAN_Fake_Akun.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZ2KHstENKU1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, LeakyReLU, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('stopwords', download_dir='path_to_download_dir')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTsHMiZVR1Co",
        "outputId": "ca153a3c-b43e-4de0-ec48-765ec2bf3426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package stopwords to path_to_download_dir...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfiLsesAPFpk"
      },
      "outputs": [],
      "source": [
        "# Load data with a different encoding\n",
        "data = pd.read_csv(\"/content/Data scrapping komentar e-commerce.csv\", encoding='ISO-8859-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGSA5lA1PMQJ"
      },
      "outputs": [],
      "source": [
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    # Join tokens\n",
        "    text = ' '.join(tokens)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pK4bOppGQT7S"
      },
      "outputs": [],
      "source": [
        "# Preprocess the 'Review' column\n",
        "data['Review /Komentar'] = data['Review /Komentar'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8hFaOn4Qjni",
        "outputId": "75660507-70fa-486f-c18c-af426670b6bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['No', 'Nama pemilik', 'Nama Toko', 'Produk', 'Nama akun pembeli',\n",
            "       'Profil gambar akun', 'Deteksi Akun', 'Review /Komentar',\n",
            "       'Rating bintang', 'Sentimen', 'Source', 'Data_Review', 'Month', 'YEAR',\n",
            "       'LINK', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18',\n",
            "       'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22',\n",
            "       'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25', 'Unnamed: 26',\n",
            "       'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29', 'Unnamed: 30',\n",
            "       'Unnamed: 31', 'Unnamed: 32', 'Unnamed: 33', 'Unnamed: 34'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Menampilkan nama-nama kolom yang ada dalam DataFrame\n",
        "print(data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6m0IQvHrtX6p"
      },
      "outputs": [],
      "source": [
        "# Find the unique words in the preprocessed text\n",
        "unique_words =set(' '.join(data['Review /Komentar']).split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jN1brMMNQbFh"
      },
      "outputs": [],
      "source": [
        "# Define constants\n",
        "latent_dim =100\n",
        "input_dim =len(unique_words) # define the input dimension based on the preprocessing step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0SbqAVdPWMM"
      },
      "outputs": [],
      "source": [
        "# Define the Generator model\n",
        "def build_generator(latent_dim):\n",
        "    model = Sequential([\n",
        "        Dense(128, input_dim=latent_dim, activation='relu'),\n",
        "        Dense(latent_dim, activation='sigmoid')\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoWq1LNKt3co"
      },
      "outputs": [],
      "source": [
        "# Define the Discriminator model\n",
        "def build_discriminator(input_dim):\n",
        "    model = Sequential([\n",
        "        Dense(256, input_dim=input_dim),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Dropout(0.25),\n",
        "        Dense(128),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Dropout(0.25),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2T7vjskjuMtE"
      },
      "outputs": [],
      "source": [
        "# Define the GAN model\n",
        "def build_gan(generator, discriminator, latent_dim):\n",
        "    discriminator.trainable = False\n",
        "\n",
        "    gan_input = tf.keras.Input(shape=(latent_dim,))\n",
        "    x = generator(gan_input)\n",
        "    gan_output = discriminator(x)\n",
        "\n",
        "    gan = Model(gan_input, gan_output)\n",
        "    gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "    return gan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlN4V_wbuRQJ",
        "outputId": "cb02df5a-38ca-4a08-af0f-0877a4bbae96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.src.engine.functional.Functional object at 0x7d1b98c4ed40>\n"
          ]
        }
      ],
      "source": [
        "# Set dimensions\n",
        "latent_dim = 100  # Example latent dimension size\n",
        "input_dim = 100   # Example input dimension size for the discriminator\n",
        "\n",
        "# Initialize models\n",
        "generator = build_generator(latent_dim)\n",
        "discriminator = build_discriminator(input_dim)\n",
        "gan = build_gan(generator, discriminator, latent_dim)\n",
        "\n",
        "print(gan)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iRHZa-SusDZ",
        "outputId": "0149d8fe-9649-4fca-92cd-808d6feca264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 [==============================] - 1s 21ms/step\n"
          ]
        }
      ],
      "source": [
        "# Generate new data using the trained generator\n",
        "generated_data = generator.predict(np.random.randn(len(data), latent_dim))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcmRr7K-uwuD",
        "outputId": "7e532628-6bb3-4086-d580-e55957f25b56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42/42 [==============================] - 0s 2ms/step\n",
            "[[0.7069435 ]\n",
            " [0.6810395 ]\n",
            " [0.664957  ]\n",
            " ...\n",
            " [0.71145535]\n",
            " [0.6988979 ]\n",
            " [0.6920153 ]]\n"
          ]
        }
      ],
      "source": [
        "# Predict whether the generated data is fake or not using the discriminator model\n",
        "predictions = discriminator.predict(generated_data)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_UjvvdXw_-y",
        "outputId": "054a4b32-5706-4106-daf9-4e0a8e620f20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Prediction Score: 0.68153805\n"
          ]
        }
      ],
      "source": [
        "# Calculate the average prediction score\n",
        "average_score = np.mean(predictions)\n",
        "print(\"Average Prediction Score:\", average_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODitn3aXu0dH"
      },
      "outputs": [],
      "source": [
        "# Convert the predictions to binary logic (1 for \"not fake\" and 0 for \"fake\")\n",
        "binary_predictions = (predictions > average_score).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_TurQtgxsSa"
      },
      "outputs": [],
      "source": [
        "# Map binary values to corresponding labels\n",
        "labels = [\"fake\" if pred == 0 else \"not fake\" for pred in binary_predictions]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s57Flli5u_Qg"
      },
      "outputs": [],
      "source": [
        "# Create ground truth labels\n",
        "num_generated_samples = len(generated_data)\n",
        "num_real_samples = len(data)\n",
        "generated_labels = np.zeros(num_generated_samples)  # Label fake data as 0\n",
        "real_labels = np.ones(num_real_samples)             # Label real data as 1\n",
        "\n",
        "# Combine generated and real labels\n",
        "ground_truth_labels = np.concatenate([generated_labels, real_labels])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0oKNNIc1uuK",
        "outputId": "7fdd5655-d495-4041-cae3-2b5483e96e7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAN Classifier Accuracy: 0.5026375282592314\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(ground_truth_labels[:len(binary_predictions)], binary_predictions)\n",
        "print(\"GAN Classifier Accuracy:\", accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}